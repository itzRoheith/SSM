name: PDF Scraper (Every 5 Minutes)

on:
  schedule:
    - cron: '*/5 * * * *'  # Runs every 5 minutes
  workflow_dispatch:

jobs:
  scrape_and_push:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3
        with:
          fetch-depth: 0  # Ensures full history is available

      - name: Set Up Python
        uses: actions/setup-python@v3
        with:
          python-version: '3.x'

      - name: Install Dependencies
        run: pip install selenium webdriver-manager requests beautifulsoup4

      - name: Run Scraper Script
        run: python scripts/scraper.py  # Ensure PDFs are saved in 'pdfs/' folder

      - name: Debug: List Downloaded Files
        run: ls -R pdfs || echo "No PDFs found"

      - name: Configure Git
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"

      - name: Pull Latest Changes (Prevent Conflicts)
        run: |
          git pull --rebase origin main || echo "No changes to rebase"

      - name: Push Changes (if any)
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          git add pdfs/*.pdf || echo "No new PDFs to add"
          git commit -m "Updated PDFs" || echo "No changes to commit"
          git push
